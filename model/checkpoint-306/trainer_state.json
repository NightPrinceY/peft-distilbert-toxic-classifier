{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 306,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 2.4592299461364746,
      "learning_rate": 4.8366013071895424e-05,
      "loss": 2.1319,
      "step": 10
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 2.894960880279541,
      "learning_rate": 4.673202614379085e-05,
      "loss": 1.9711,
      "step": 20
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 3.3893532752990723,
      "learning_rate": 4.5098039215686275e-05,
      "loss": 1.8144,
      "step": 30
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 2.4886956214904785,
      "learning_rate": 4.3464052287581704e-05,
      "loss": 1.6312,
      "step": 40
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 2.55887508392334,
      "learning_rate": 4.1830065359477126e-05,
      "loss": 1.5245,
      "step": 50
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 2.4285619258880615,
      "learning_rate": 4.0196078431372555e-05,
      "loss": 1.3634,
      "step": 60
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 3.592928171157837,
      "learning_rate": 3.8562091503267977e-05,
      "loss": 1.4238,
      "step": 70
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 4.096268177032471,
      "learning_rate": 3.6928104575163405e-05,
      "loss": 1.0612,
      "step": 80
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 2.062758445739746,
      "learning_rate": 3.529411764705883e-05,
      "loss": 1.1218,
      "step": 90
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 2.8075952529907227,
      "learning_rate": 3.366013071895425e-05,
      "loss": 0.9378,
      "step": 100
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 2.4786593914031982,
      "learning_rate": 3.202614379084967e-05,
      "loss": 0.9663,
      "step": 110
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 2.653073310852051,
      "learning_rate": 3.0392156862745097e-05,
      "loss": 0.9203,
      "step": 120
    },
    {
      "epoch": 1.2745098039215685,
      "grad_norm": 2.6596646308898926,
      "learning_rate": 2.8758169934640522e-05,
      "loss": 0.8243,
      "step": 130
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 2.3254425525665283,
      "learning_rate": 2.7124183006535947e-05,
      "loss": 0.652,
      "step": 140
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 3.7160348892211914,
      "learning_rate": 2.5490196078431373e-05,
      "loss": 0.7531,
      "step": 150
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 2.2945919036865234,
      "learning_rate": 2.38562091503268e-05,
      "loss": 0.7141,
      "step": 160
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 2.169950008392334,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.5894,
      "step": 170
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 2.6839427947998047,
      "learning_rate": 2.058823529411765e-05,
      "loss": 0.6076,
      "step": 180
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 2.0275115966796875,
      "learning_rate": 1.895424836601307e-05,
      "loss": 0.6631,
      "step": 190
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 1.7988197803497314,
      "learning_rate": 1.7320261437908496e-05,
      "loss": 0.5397,
      "step": 200
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 2.2677414417266846,
      "learning_rate": 1.568627450980392e-05,
      "loss": 0.4445,
      "step": 210
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 1.6205854415893555,
      "learning_rate": 1.4052287581699347e-05,
      "loss": 0.3826,
      "step": 220
    },
    {
      "epoch": 2.2549019607843137,
      "grad_norm": 3.0127856731414795,
      "learning_rate": 1.2418300653594772e-05,
      "loss": 0.3774,
      "step": 230
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 2.621312379837036,
      "learning_rate": 1.0784313725490197e-05,
      "loss": 0.5698,
      "step": 240
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 2.024254560470581,
      "learning_rate": 9.150326797385621e-06,
      "loss": 0.5562,
      "step": 250
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 2.033442974090576,
      "learning_rate": 7.5163398692810456e-06,
      "loss": 0.5305,
      "step": 260
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 2.4561281204223633,
      "learning_rate": 5.882352941176471e-06,
      "loss": 0.4411,
      "step": 270
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 2.631648302078247,
      "learning_rate": 4.2483660130718954e-06,
      "loss": 0.5045,
      "step": 280
    },
    {
      "epoch": 2.843137254901961,
      "grad_norm": 1.4978042840957642,
      "learning_rate": 2.6143790849673204e-06,
      "loss": 0.3542,
      "step": 290
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 1.9586273431777954,
      "learning_rate": 9.80392156862745e-07,
      "loss": 0.3905,
      "step": 300
    }
  ],
  "logging_steps": 10,
  "max_steps": 306,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 192011299875000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
